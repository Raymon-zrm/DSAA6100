{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-10T16:15:36.916032Z","iopub.status.busy":"2023-09-10T16:15:36.915615Z","iopub.status.idle":"2023-09-10T16:15:36.925735Z","shell.execute_reply":"2023-09-10T16:15:36.924599Z","shell.execute_reply.started":"2023-09-10T16:15:36.916001Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'pandas'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m/Users/raymon/HKUSTGZ-DSAA6100/02-ML/Kaggle Turorial - Linear Model.ipynb 单元格 1\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/raymon/HKUSTGZ-DSAA6100/02-ML/Kaggle%20Turorial%20-%20Linear%20Model.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# This Python 3 environment comes with many helpful analytics libraries installed\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/raymon/HKUSTGZ-DSAA6100/02-ML/Kaggle%20Turorial%20-%20Linear%20Model.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/raymon/HKUSTGZ-DSAA6100/02-ML/Kaggle%20Turorial%20-%20Linear%20Model.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# For example, here's several helpful packages to load\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/raymon/HKUSTGZ-DSAA6100/02-ML/Kaggle%20Turorial%20-%20Linear%20Model.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m \u001b[39m# linear algebra\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/raymon/HKUSTGZ-DSAA6100/02-ML/Kaggle%20Turorial%20-%20Linear%20Model.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \u001b[39m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/raymon/HKUSTGZ-DSAA6100/02-ML/Kaggle%20Turorial%20-%20Linear%20Model.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Input data files are available in the read-only \"../input/\" directory\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/raymon/HKUSTGZ-DSAA6100/02-ML/Kaggle%20Turorial%20-%20Linear%20Model.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raymon/HKUSTGZ-DSAA6100/02-ML/Kaggle%20Turorial%20-%20Linear%20Model.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["# Loading Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:36.928692Z","iopub.status.busy":"2023-09-10T16:15:36.928218Z","iopub.status.idle":"2023-09-10T16:15:36.948952Z","shell.execute_reply":"2023-09-10T16:15:36.947549Z","shell.execute_reply.started":"2023-09-10T16:15:36.928613Z"},"trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31m无法启动 Kernel。 \n","\u001b[1;31mUnable to start Kernel 'dsaa5021 (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import pandas as pd\n","\n","df = pd.read_csv('/kaggle/input/titanic/train.csv')"]},{"cell_type":"markdown","metadata":{},"source":["## Display data"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:36.951356Z","iopub.status.busy":"2023-09-10T16:15:36.950650Z","iopub.status.idle":"2023-09-10T16:15:36.975946Z","shell.execute_reply":"2023-09-10T16:15:36.975119Z","shell.execute_reply.started":"2023-09-10T16:15:36.951139Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>886</th>\n","      <td>887</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Montvila, Rev. Juozas</td>\n","      <td>male</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>211536</td>\n","      <td>13.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>888</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Graham, Miss. Margaret Edith</td>\n","      <td>female</td>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>112053</td>\n","      <td>30.0000</td>\n","      <td>B42</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>889</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n","      <td>female</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>W./C. 6607</td>\n","      <td>23.4500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>890</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Behr, Mr. Karl Howell</td>\n","      <td>male</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>111369</td>\n","      <td>30.0000</td>\n","      <td>C148</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>891</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Dooley, Mr. Patrick</td>\n","      <td>male</td>\n","      <td>32.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>370376</td>\n","      <td>7.7500</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows × 12 columns</p>\n","</div>"],"text/plain":["     PassengerId  Survived  Pclass  \\\n","0              1         0       3   \n","1              2         1       1   \n","2              3         1       3   \n","3              4         1       1   \n","4              5         0       3   \n","..           ...       ...     ...   \n","886          887         0       2   \n","887          888         1       1   \n","888          889         0       3   \n","889          890         1       1   \n","890          891         0       3   \n","\n","                                                    Name     Sex   Age  SibSp  \\\n","0                                Braund, Mr. Owen Harris    male  22.0      1   \n","1    Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n","2                                 Heikkinen, Miss. Laina  female  26.0      0   \n","3           Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                               Allen, Mr. William Henry    male  35.0      0   \n","..                                                   ...     ...   ...    ...   \n","886                                Montvila, Rev. Juozas    male  27.0      0   \n","887                         Graham, Miss. Margaret Edith  female  19.0      0   \n","888             Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n","889                                Behr, Mr. Karl Howell    male  26.0      0   \n","890                                  Dooley, Mr. Patrick    male  32.0      0   \n","\n","     Parch            Ticket     Fare Cabin Embarked  \n","0        0         A/5 21171   7.2500   NaN        S  \n","1        0          PC 17599  71.2833   C85        C  \n","2        0  STON/O2. 3101282   7.9250   NaN        S  \n","3        0            113803  53.1000  C123        S  \n","4        0            373450   8.0500   NaN        S  \n","..     ...               ...      ...   ...      ...  \n","886      0            211536  13.0000   NaN        S  \n","887      0            112053  30.0000   B42        S  \n","888      2        W./C. 6607  23.4500   NaN        S  \n","889      0            111369  30.0000  C148        C  \n","890      0            370376   7.7500   NaN        Q  \n","\n","[891 rows x 12 columns]"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{},"source":["## Data Cleaning"]},{"cell_type":"markdown","metadata":{},"source":["There are some missing values in the csv file. Pandas will put a NaN in the missing locations."]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:36.978165Z","iopub.status.busy":"2023-09-10T16:15:36.977387Z","iopub.status.idle":"2023-09-10T16:15:36.987873Z","shell.execute_reply":"2023-09-10T16:15:36.986434Z","shell.execute_reply.started":"2023-09-10T16:15:36.978131Z"},"trusted":true},"outputs":[{"data":{"text/plain":["PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age            177\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","Cabin          687\n","Embarked         2\n","dtype: int64"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["Next, we need to replace the NaN with something. A common used way is to replace them with mode values."]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:36.992358Z","iopub.status.busy":"2023-09-10T16:15:36.991601Z","iopub.status.idle":"2023-09-10T16:15:37.026837Z","shell.execute_reply":"2023-09-10T16:15:37.025692Z","shell.execute_reply.started":"2023-09-10T16:15:36.992317Z"},"trusted":true},"outputs":[{"data":{"text/plain":["PassengerId                      1\n","Survived                       0.0\n","Pclass                         3.0\n","Name           Abbing, Mr. Anthony\n","Sex                           male\n","Age                           24.0\n","SibSp                          0.0\n","Parch                          0.0\n","Ticket                        1601\n","Fare                          8.05\n","Cabin                      B96 B98\n","Embarked                         S\n","Name: 0, dtype: object"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["modes = df.mode().iloc[0]\n","modes"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.029482Z","iopub.status.busy":"2023-09-10T16:15:37.028690Z","iopub.status.idle":"2023-09-10T16:15:37.042027Z","shell.execute_reply":"2023-09-10T16:15:37.040465Z","shell.execute_reply.started":"2023-09-10T16:15:37.029441Z"},"trusted":true},"outputs":[],"source":["df.fillna(modes, inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["We can now check there's no missing values left:"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.044491Z","iopub.status.busy":"2023-09-10T16:15:37.043749Z","iopub.status.idle":"2023-09-10T16:15:37.058427Z","shell.execute_reply":"2023-09-10T16:15:37.057337Z","shell.execute_reply.started":"2023-09-10T16:15:37.044448Z"},"trusted":true},"outputs":[{"data":{"text/plain":["PassengerId    0\n","Survived       0\n","Pclass         0\n","Name           0\n","Sex            0\n","Age            0\n","SibSp          0\n","Parch          0\n","Ticket         0\n","Fare           0\n","Cabin          0\n","Embarked       0\n","dtype: int64"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["The summary of the dataset:"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.060707Z","iopub.status.busy":"2023-09-10T16:15:37.060193Z","iopub.status.idle":"2023-09-10T16:15:37.101097Z","shell.execute_reply":"2023-09-10T16:15:37.099946Z","shell.execute_reply.started":"2023-09-10T16:15:37.060675Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>446.000000</td>\n","      <td>0.383838</td>\n","      <td>2.308642</td>\n","      <td>28.566970</td>\n","      <td>0.523008</td>\n","      <td>0.381594</td>\n","      <td>32.204208</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>257.353842</td>\n","      <td>0.486592</td>\n","      <td>0.836071</td>\n","      <td>13.199572</td>\n","      <td>1.102743</td>\n","      <td>0.806057</td>\n","      <td>49.693429</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.420000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>223.500000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>22.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.910400</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>446.000000</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>24.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>14.454200</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>668.500000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>35.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>31.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>891.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>80.000000</td>\n","      <td>8.000000</td>\n","      <td>6.000000</td>\n","      <td>512.329200</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       PassengerId    Survived      Pclass         Age       SibSp  \\\n","count   891.000000  891.000000  891.000000  891.000000  891.000000   \n","mean    446.000000    0.383838    2.308642   28.566970    0.523008   \n","std     257.353842    0.486592    0.836071   13.199572    1.102743   \n","min       1.000000    0.000000    1.000000    0.420000    0.000000   \n","25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n","50%     446.000000    0.000000    3.000000   24.000000    0.000000   \n","75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n","max     891.000000    1.000000    3.000000   80.000000    8.000000   \n","\n","            Parch        Fare  \n","count  891.000000  891.000000  \n","mean     0.381594   32.204208  \n","std      0.806057   49.693429  \n","min      0.000000    0.000000  \n","25%      0.000000    7.910400  \n","50%      0.000000   14.454200  \n","75%      0.000000   31.000000  \n","max      6.000000  512.329200  "]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","\n","df.describe(include=(np.number))"]},{"cell_type":"markdown","metadata":{},"source":["Print the summary of non-numeric columns in the dataset."]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.102851Z","iopub.status.busy":"2023-09-10T16:15:37.102346Z","iopub.status.idle":"2023-09-10T16:15:37.122734Z","shell.execute_reply":"2023-09-10T16:15:37.121107Z","shell.execute_reply.started":"2023-09-10T16:15:37.102818Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Ticket</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>891</td>\n","      <td>2</td>\n","      <td>681</td>\n","      <td>147</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>347082</td>\n","      <td>B96 B98</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>577</td>\n","      <td>7</td>\n","      <td>691</td>\n","      <td>646</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           Name   Sex  Ticket    Cabin Embarked\n","count                       891   891     891      891      891\n","unique                      891     2     681      147        3\n","top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n","freq                          1   577       7      691      646"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["df.describe(include=[object])"]},{"cell_type":"markdown","metadata":{},"source":["## Data Preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["Obviously, we can not multiply non-numeric values by coefficients, so we need to replace those with numbers.\n","\n","We do that by creating new columns containing dummy variables. A dummy variable is a column that contains a 1 where a particular column contains a particular value, or a 0 otherwise.\n","\n","For instance, we could create a dummy variable for `Sex='male'`, which would be a new column containing 1 for rows where Sex is 'male', and 0 for rows where it isn't.\n","\n","Pandas can create these automatically using `get_dummies`, which also remove the original columns. We'll create dummy variables for `Pclass`, even although it's numeric, since the numbers 1, 2, and 3 correspond to first, second, and third class cabins - not to counts or measures that make sense to multiply by. We'll also create dummies for `Sex` and `Embarked` since we'll want to use those as predictors in our model. On the other hand, `Cabin`, `Name`, and `Ticket` have too many unique values for it to make sense creating dummy variables for them."]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.124791Z","iopub.status.busy":"2023-09-10T16:15:37.124352Z","iopub.status.idle":"2023-09-10T16:15:37.137523Z","shell.execute_reply":"2023-09-10T16:15:37.136639Z","shell.execute_reply.started":"2023-09-10T16:15:37.124751Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket',\n","       'Fare', 'Cabin', 'Sex_female', 'Sex_male', 'Pclass_1', 'Pclass_2',\n","       'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n","      dtype='object')"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.get_dummies(df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n","df.columns"]},{"cell_type":"markdown","metadata":{},"source":["Let's look at some of the added columns and values."]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.141398Z","iopub.status.busy":"2023-09-10T16:15:37.140455Z","iopub.status.idle":"2023-09-10T16:15:37.157639Z","shell.execute_reply":"2023-09-10T16:15:37.156497Z","shell.execute_reply.started":"2023-09-10T16:15:37.141362Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex_male</th>\n","      <th>Sex_female</th>\n","      <th>Pclass_1</th>\n","      <th>Pclass_2</th>\n","      <th>Pclass_3</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  \\\n","0         1           0         0         0         1           0           0   \n","1         0           1         1         0         0           1           0   \n","2         0           1         0         0         1           0           0   \n","3         0           1         1         0         0           0           0   \n","4         1           0         0         0         1           0           0   \n","\n","   Embarked_S  \n","0           1  \n","1           0  \n","2           1  \n","3           1  \n","4           1  "]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["added_cols = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n","df[added_cols] = df[added_cols].astype(int)\n","df[added_cols].head()"]},{"cell_type":"markdown","metadata":{},"source":["The target variable (label) is `Survived` and the others are as model input."]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.160942Z","iopub.status.busy":"2023-09-10T16:15:37.160156Z","iopub.status.idle":"2023-09-10T16:15:37.176605Z","shell.execute_reply":"2023-09-10T16:15:37.175282Z","shell.execute_reply.started":"2023-09-10T16:15:37.160896Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input shape:  torch.Size([891, 12])\n","Target shape torch.Size([891])\n"]}],"source":["import torch\n","\n","Y = torch.tensor(df.Survived)\n","\n","indep_cols = ['Age', 'SibSp', 'Parch', 'Fare'] + added_cols\n","X = torch.tensor(df[indep_cols].values, dtype=torch.float)\n","\n","print('Input shape: ', X.shape)\n","print('Target shape', Y.shape)"]},{"cell_type":"markdown","metadata":{},"source":["# Building a linear model"]},{"cell_type":"markdown","metadata":{},"source":["$$\n","Y = WX\n","$$"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.178073Z","iopub.status.busy":"2023-09-10T16:15:37.177736Z","iopub.status.idle":"2023-09-10T16:15:37.193066Z","shell.execute_reply":"2023-09-10T16:15:37.191851Z","shell.execute_reply.started":"2023-09-10T16:15:37.178044Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["W shape:  torch.Size([12])\n","tensor([-0.0037,  0.2682, -0.4115, -0.3680, -0.1926,  0.1341, -0.0099,  0.3964,\n","        -0.0444,  0.1323, -0.1511, -0.0983])\n"]}],"source":["torch.manual_seed(0)\n","\n","num_features = X.shape[1]\n","W = torch.rand(num_features)-0.5\n","\n","print('W shape: ', W.shape)\n","print(W)"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.196036Z","iopub.status.busy":"2023-09-10T16:15:37.195628Z","iopub.status.idle":"2023-09-10T16:15:37.203663Z","shell.execute_reply":"2023-09-10T16:15:37.202486Z","shell.execute_reply.started":"2023-09-10T16:15:37.195999Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["pred shape:  torch.Size([891])\n","tensor([ -2.8171, -25.8476,  -3.0221, -19.3761,  -3.4284,  -3.5903, -19.5867,\n","         -7.7045,  -5.0294, -10.1865])\n"]}],"source":["pred = torch.matmul(W, X.T)\n","\n","print('pred shape: ', pred.shape)\n","print(pred[:10])"]},{"cell_type":"markdown","metadata":{},"source":["The model weights are generated randomly. So the current predictions are not going to be any use. To train the linear model, we need to define the loss firstly. Here, we simply use the absolute error as the loss."]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.205817Z","iopub.status.busy":"2023-09-10T16:15:37.205093Z","iopub.status.idle":"2023-09-10T16:15:37.214458Z","shell.execute_reply":"2023-09-10T16:15:37.213380Z","shell.execute_reply.started":"2023-09-10T16:15:37.205786Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["loss:  tensor(12.4397)\n"]}],"source":["loss = torch.abs(pred - Y).mean()\n","\n","print('loss: ', loss)"]},{"cell_type":"markdown","metadata":{},"source":["Leverage PyTorch to calculate the gradients. We need to call the function `requires_grad_` before calculating loss."]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.216619Z","iopub.status.busy":"2023-09-10T16:15:37.216129Z","iopub.status.idle":"2023-09-10T16:15:37.225032Z","shell.execute_reply":"2023-09-10T16:15:37.224277Z","shell.execute_reply.started":"2023-09-10T16:15:37.216579Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([-0.0037,  0.2682, -0.4115, -0.3680, -0.1926,  0.1341, -0.0099,  0.3964,\n","        -0.0444,  0.1323, -0.1511, -0.0983], requires_grad=True)"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["W.requires_grad_()"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.226231Z","iopub.status.busy":"2023-09-10T16:15:37.225903Z","iopub.status.idle":"2023-09-10T16:15:37.239033Z","shell.execute_reply":"2023-09-10T16:15:37.237836Z","shell.execute_reply.started":"2023-09-10T16:15:37.226204Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([-28.2437,  -0.5230,  -0.3816, -32.2042,  -0.6341,  -0.3524,  -0.2424,\n","         -0.1930,  -0.5511,  -0.1886,  -0.0864,  -0.7116])\n"]}],"source":["pred = torch.matmul(W, X.T)\n","loss = torch.abs(pred - Y).mean()\n","\n","loss.backward()\n","\n","print(W.grad)"]},{"cell_type":"markdown","metadata":{},"source":["Notice that the gradients will be accumulated by default. Therefore, if we don't want the gradients to be accumulated, we should clear the gradients by call the `zero_` function of the gradients object after updating the model parameters."]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.241350Z","iopub.status.busy":"2023-09-10T16:15:37.240952Z","iopub.status.idle":"2023-09-10T16:15:37.247275Z","shell.execute_reply":"2023-09-10T16:15:37.246017Z","shell.execute_reply.started":"2023-09-10T16:15:37.241310Z"},"trusted":true},"outputs":[],"source":["learning_rate = 0.1\n","with torch.no_grad():\n","    W.sub_(W.grad * learning_rate)\n","    W.grad.zero_()"]},{"cell_type":"markdown","metadata":{},"source":["# Model Training"]},{"cell_type":"markdown","metadata":{},"source":["Before model training, we should split the dataset into two parts: one for training (training set) and one for validation (validation set). Training set is used to train the model, and the validation set is used to evaluate the performance of the current model.\n","\n","It is not resonable to evaluate the model according to the performance of the model on the training set since the model has seen the training set. It is better to use another dataset that the model has not seen. That's why we split the dataset into training set and validation set."]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.248877Z","iopub.status.busy":"2023-09-10T16:15:37.248548Z","iopub.status.idle":"2023-09-10T16:15:37.265047Z","shell.execute_reply":"2023-09-10T16:15:37.263819Z","shell.execute_reply.started":"2023-09-10T16:15:37.248848Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["#Training set:  713\n","#Validation set:  178\n"]}],"source":["from fastai.data.transforms import RandomSplitter\n","\n","trn_split, val_split = RandomSplitter(seed=0, valid_pct=0.2)(df)\n","trn_X,val_X = X[trn_split],X[val_split]\n","trn_Y,val_Y = Y[trn_split],Y[val_split]\n","\n","vals, indices = trn_X.max(dim=0)\n","trn_X = trn_X / vals\n","vals, indices = val_X.max(dim=0)\n","val_X = val_X / vals\n","\n","print('#Training set: ', len(trn_X))\n","print('#Validation set: ', len(val_X))"]},{"cell_type":"markdown","metadata":{},"source":["Start training now! Let's define some functions:"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.267085Z","iopub.status.busy":"2023-09-10T16:15:37.266681Z","iopub.status.idle":"2023-09-10T16:15:37.275994Z","shell.execute_reply":"2023-09-10T16:15:37.274978Z","shell.execute_reply.started":"2023-09-10T16:15:37.267052Z"},"trusted":true},"outputs":[],"source":["def predict(W, x):\n","    return torch.matmul(W, x.T)\n","\n","def loss_fn(pred, target):\n","    return torch.abs(pred - target).mean()\n","\n","def optimize(W, learning_rate):\n","    W.sub_(W.grad * learning_rate)\n","    W.grad.zero_()\n","\n","def one_epoch(W, x, y, learning_rate):\n","    pred = predict(W, x)\n","    loss = loss_fn(pred, y)\n","    loss.backward()\n","    with torch.no_grad():\n","        optimize(W, learning_rate)\n","    return loss.item()\n","\n","def init_w(num_features):\n","    W = torch.rand(num_features)-0.5\n","    W.requires_grad_()\n","    return W\n","\n","def train_model(X, Y, epochs=50, lr=0.0005):\n","    torch.manual_seed(0)\n","    W = init_w(X.shape[1])\n","    for i in range(epochs):\n","        loss = one_epoch(W, X, Y, learning_rate=lr)\n","    print('Final loss: ', loss)\n","    return W"]},{"cell_type":"markdown","metadata":{},"source":["Then we can train a model by calling the `train_model` function."]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:18:26.423608Z","iopub.status.busy":"2023-09-10T16:18:26.423203Z","iopub.status.idle":"2023-09-10T16:18:26.635353Z","shell.execute_reply":"2023-09-10T16:18:26.634158Z","shell.execute_reply.started":"2023-09-10T16:18:26.423577Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Final loss:  0.2253539115190506\n"]}],"source":["W = train_model(trn_X, trn_Y, 1000, 0.005)"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{},"source":["Use the model to predict the results on the validation set."]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:15:37.508157Z","iopub.status.busy":"2023-09-10T16:15:37.507636Z","iopub.status.idle":"2023-09-10T16:15:37.516847Z","shell.execute_reply":"2023-09-10T16:15:37.515706Z","shell.execute_reply.started":"2023-09-10T16:15:37.508126Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss:  tensor(0.2580, grad_fn=<MeanBackward0>)\n","Pred:  tensor([-0.0070, -0.0012, -0.0353, -0.0821,  0.9842, -0.1535, -0.1110,  1.0112,\n","         0.9232,  0.0073], grad_fn=<SliceBackward0>)\n","Target:  tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 1])\n","Accuracy:  0.7696629166603088\n"]}],"source":["pred = predict(W, val_X)\n","loss = loss_fn(pred, val_Y)\n","\n","results = val_Y.bool() == (pred > 0.5)\n","\n","print('Loss: ', loss)\n","print('Pred: ', pred[:10])\n","print('Target: ', val_Y[:10])\n","print('Accuracy: ', results.float().mean().item())"]},{"cell_type":"markdown","metadata":{},"source":["# Submitting to Kaggle"]},{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:16:24.432696Z","iopub.status.busy":"2023-09-10T16:16:24.432291Z","iopub.status.idle":"2023-09-10T16:16:24.442637Z","shell.execute_reply":"2023-09-10T16:16:24.441468Z","shell.execute_reply.started":"2023-09-10T16:16:24.432660Z"},"trusted":true},"outputs":[],"source":["tst_df = pd.read_csv('/kaggle/input/titanic/test.csv')"]},{"cell_type":"markdown","metadata":{},"source":["In this case, it turns out that the test set is missing Fare for one passenger. We'll just fill it with 0 to avoid problems:"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:16:25.963400Z","iopub.status.busy":"2023-09-10T16:16:25.962979Z","iopub.status.idle":"2023-09-10T16:16:25.970379Z","shell.execute_reply":"2023-09-10T16:16:25.968934Z","shell.execute_reply.started":"2023-09-10T16:16:25.963368Z"},"trusted":true},"outputs":[],"source":["tst_df['Fare'] = tst_df.Fare.fillna(0)"]},{"cell_type":"markdown","metadata":{},"source":["Now we can just copy the same steps we did to our training set and do the same exact things on our test set to preprocess the data:"]},{"cell_type":"code","execution_count":91,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:16:28.441780Z","iopub.status.busy":"2023-09-10T16:16:28.440758Z","iopub.status.idle":"2023-09-10T16:16:28.462678Z","shell.execute_reply":"2023-09-10T16:16:28.461698Z","shell.execute_reply.started":"2023-09-10T16:16:28.441741Z"},"trusted":true},"outputs":[],"source":["tst_df.fillna(modes, inplace=True)\n","tst_df = pd.get_dummies(tst_df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n","tst_df[added_cols] = tst_df[added_cols].astype(int)\n","tst_X = torch.tensor(tst_df[indep_cols].values, dtype=torch.float)\n","vals, indices = tst_X.max(dim=0)\n","tst_X = tst_X / vals"]},{"cell_type":"markdown","metadata":{},"source":["Let's calculate our predictions of which passengers survived in the test set:"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:16:31.321834Z","iopub.status.busy":"2023-09-10T16:16:31.321104Z","iopub.status.idle":"2023-09-10T16:16:31.327593Z","shell.execute_reply":"2023-09-10T16:16:31.326515Z","shell.execute_reply.started":"2023-09-10T16:16:31.321798Z"},"trusted":true},"outputs":[],"source":["tst_df['Survived'] = (predict(tst_X, W) > 0.5).int()"]},{"cell_type":"markdown","metadata":{},"source":["The sample submission on the Kaggle competition site shows that we're expected to upload a CSV with just `PassengerId` and `Survived`, so let's create that and save it:"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:16:34.327704Z","iopub.status.busy":"2023-09-10T16:16:34.326985Z","iopub.status.idle":"2023-09-10T16:16:34.335533Z","shell.execute_reply":"2023-09-10T16:16:34.334209Z","shell.execute_reply.started":"2023-09-10T16:16:34.327668Z"},"trusted":true},"outputs":[],"source":["sub_df = tst_df[['PassengerId','Survived']]\n","sub_df.to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["We can check the first few rows of the file to make sure it looks reasonable:"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2023-09-10T16:16:39.899094Z","iopub.status.busy":"2023-09-10T16:16:39.898705Z","iopub.status.idle":"2023-09-10T16:16:40.919541Z","shell.execute_reply":"2023-09-10T16:16:40.918269Z","shell.execute_reply.started":"2023-09-10T16:16:39.899063Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["PassengerId,Survived\n","892,0\n","893,1\n","894,0\n","895,0\n","896,1\n","897,0\n","898,1\n","899,0\n","900,1\n"]}],"source":["!head submission.csv"]},{"cell_type":"markdown","metadata":{},"source":["When you click \"Submit\" in Kaggle, and wait for the notebook to run, you'll see that your results have been submitted to the competition."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
