{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-10T16:15:36.915615Z","iopub.execute_input":"2023-09-10T16:15:36.916032Z","iopub.status.idle":"2023-09-10T16:15:36.925735Z","shell.execute_reply.started":"2023-09-10T16:15:36.916001Z","shell.execute_reply":"2023-09-10T16:15:36.924599Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/input/titanic/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:36.928218Z","iopub.execute_input":"2023-09-10T16:15:36.928692Z","iopub.status.idle":"2023-09-10T16:15:36.948952Z","shell.execute_reply.started":"2023-09-10T16:15:36.928613Z","shell.execute_reply":"2023-09-10T16:15:36.947549Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"## Display data","metadata":{}},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:36.950650Z","iopub.execute_input":"2023-09-10T16:15:36.951356Z","iopub.status.idle":"2023-09-10T16:15:36.975946Z","shell.execute_reply.started":"2023-09-10T16:15:36.951139Z","shell.execute_reply":"2023-09-10T16:15:36.975119Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                    Name     Sex   Age  SibSp  \\\n0                                Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n2                                 Heikkinen, Miss. Laina  female  26.0      0   \n3           Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                               Allen, Mr. William Henry    male  35.0      0   \n..                                                   ...     ...   ...    ...   \n886                                Montvila, Rev. Juozas    male  27.0      0   \n887                         Graham, Miss. Margaret Edith  female  19.0      0   \n888             Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n889                                Behr, Mr. Karl Howell    male  26.0      0   \n890                                  Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked  \n0        0         A/5 21171   7.2500   NaN        S  \n1        0          PC 17599  71.2833   C85        C  \n2        0  STON/O2. 3101282   7.9250   NaN        S  \n3        0            113803  53.1000  C123        S  \n4        0            373450   8.0500   NaN        S  \n..     ...               ...      ...   ...      ...  \n886      0            211536  13.0000   NaN        S  \n887      0            112053  30.0000   B42        S  \n888      2        W./C. 6607  23.4500   NaN        S  \n889      0            111369  30.0000  C148        C  \n890      0            370376   7.7500   NaN        Q  \n\n[891 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows Ã— 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"There are some missing values in the csv file. Pandas will put a NaN in the missing locations.","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:36.977387Z","iopub.execute_input":"2023-09-10T16:15:36.978165Z","iopub.status.idle":"2023-09-10T16:15:36.987873Z","shell.execute_reply.started":"2023-09-10T16:15:36.978131Z","shell.execute_reply":"2023-09-10T16:15:36.986434Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"Next, we need to replace the NaN with something. A common used way is to replace them with mode values.","metadata":{}},{"cell_type":"code","source":"modes = df.mode().iloc[0]\nmodes","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:36.991601Z","iopub.execute_input":"2023-09-10T16:15:36.992358Z","iopub.status.idle":"2023-09-10T16:15:37.026837Z","shell.execute_reply.started":"2023-09-10T16:15:36.992317Z","shell.execute_reply":"2023-09-10T16:15:37.025692Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"PassengerId                      1\nSurvived                       0.0\nPclass                         3.0\nName           Abbing, Mr. Anthony\nSex                           male\nAge                           24.0\nSibSp                          0.0\nParch                          0.0\nTicket                        1601\nFare                          8.05\nCabin                      B96 B98\nEmbarked                         S\nName: 0, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df.fillna(modes, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.028690Z","iopub.execute_input":"2023-09-10T16:15:37.029482Z","iopub.status.idle":"2023-09-10T16:15:37.042027Z","shell.execute_reply.started":"2023-09-10T16:15:37.029441Z","shell.execute_reply":"2023-09-10T16:15:37.040465Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"We can now check there's no missing values left:","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.043749Z","iopub.execute_input":"2023-09-10T16:15:37.044491Z","iopub.status.idle":"2023-09-10T16:15:37.058427Z","shell.execute_reply.started":"2023-09-10T16:15:37.044448Z","shell.execute_reply":"2023-09-10T16:15:37.057337Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"PassengerId    0\nSurvived       0\nPclass         0\nName           0\nSex            0\nAge            0\nSibSp          0\nParch          0\nTicket         0\nFare           0\nCabin          0\nEmbarked       0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"The summary of the dataset:","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndf.describe(include=(np.number))","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.060193Z","iopub.execute_input":"2023-09-10T16:15:37.060707Z","iopub.status.idle":"2023-09-10T16:15:37.101097Z","shell.execute_reply.started":"2023-09-10T16:15:37.060675Z","shell.execute_reply":"2023-09-10T16:15:37.099946Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   891.000000  891.000000  891.000000  891.000000  891.000000   \nmean    446.000000    0.383838    2.308642   28.566970    0.523008   \nstd     257.353842    0.486592    0.836071   13.199572    1.102743   \nmin       1.000000    0.000000    1.000000    0.420000    0.000000   \n25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n50%     446.000000    0.000000    3.000000   24.000000    0.000000   \n75%     668.500000    1.000000    3.000000   35.000000    1.000000   \nmax     891.000000    1.000000    3.000000   80.000000    8.000000   \n\n            Parch        Fare  \ncount  891.000000  891.000000  \nmean     0.381594   32.204208  \nstd      0.806057   49.693429  \nmin      0.000000    0.000000  \n25%      0.000000    7.910400  \n50%      0.000000   14.454200  \n75%      0.000000   31.000000  \nmax      6.000000  512.329200  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>446.000000</td>\n      <td>0.383838</td>\n      <td>2.308642</td>\n      <td>28.566970</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>32.204208</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>257.353842</td>\n      <td>0.486592</td>\n      <td>0.836071</td>\n      <td>13.199572</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>49.693429</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>223.500000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.910400</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>446.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>24.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>14.454200</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>668.500000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>35.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>891.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>512.329200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Print the summary of non-numeric columns in the dataset.","metadata":{}},{"cell_type":"code","source":"df.describe(include=[object])","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.102346Z","iopub.execute_input":"2023-09-10T16:15:37.102851Z","iopub.status.idle":"2023-09-10T16:15:37.122734Z","shell.execute_reply.started":"2023-09-10T16:15:37.102818Z","shell.execute_reply":"2023-09-10T16:15:37.121107Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"                           Name   Sex  Ticket    Cabin Embarked\ncount                       891   891     891      891      891\nunique                      891     2     681      147        3\ntop     Braund, Mr. Owen Harris  male  347082  B96 B98        S\nfreq                          1   577       7      691      646","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Ticket</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891</td>\n      <td>891</td>\n      <td>891</td>\n      <td>891</td>\n      <td>891</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>891</td>\n      <td>2</td>\n      <td>681</td>\n      <td>147</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>347082</td>\n      <td>B96 B98</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>577</td>\n      <td>7</td>\n      <td>691</td>\n      <td>646</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Obviously, we can not multiply non-numeric values by coefficients, so we need to replace those with numbers.\n\nWe do that by creating new columns containing dummy variables. A dummy variable is a column that contains a 1 where a particular column contains a particular value, or a 0 otherwise.\n\nFor instance, we could create a dummy variable for `Sex='male'`, which would be a new column containing 1 for rows where Sex is 'male', and 0 for rows where it isn't.\n\nPandas can create these automatically using `get_dummies`, which also remove the original columns. We'll create dummy variables for `Pclass`, even although it's numeric, since the numbers 1, 2, and 3 correspond to first, second, and third class cabins - not to counts or measures that make sense to multiply by. We'll also create dummies for `Sex` and `Embarked` since we'll want to use those as predictors in our model. On the other hand, `Cabin`, `Name`, and `Ticket` have too many unique values for it to make sense creating dummy variables for them.","metadata":{}},{"cell_type":"code","source":"df = pd.get_dummies(df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.124352Z","iopub.execute_input":"2023-09-10T16:15:37.124791Z","iopub.status.idle":"2023-09-10T16:15:37.137523Z","shell.execute_reply.started":"2023-09-10T16:15:37.124751Z","shell.execute_reply":"2023-09-10T16:15:37.136639Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket',\n       'Fare', 'Cabin', 'Sex_female', 'Sex_male', 'Pclass_1', 'Pclass_2',\n       'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's look at some of the added columns and values.","metadata":{}},{"cell_type":"code","source":"added_cols = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\ndf[added_cols] = df[added_cols].astype(int)\ndf[added_cols].head()","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.140455Z","iopub.execute_input":"2023-09-10T16:15:37.141398Z","iopub.status.idle":"2023-09-10T16:15:37.157639Z","shell.execute_reply.started":"2023-09-10T16:15:37.141362Z","shell.execute_reply":"2023-09-10T16:15:37.156497Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"   Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  \\\n0         1           0         0         0         1           0           0   \n1         0           1         1         0         0           1           0   \n2         0           1         0         0         1           0           0   \n3         0           1         1         0         0           0           0   \n4         1           0         0         0         1           0           0   \n\n   Embarked_S  \n0           1  \n1           0  \n2           1  \n3           1  \n4           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex_male</th>\n      <th>Sex_female</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The target variable (label) is `Survived` and the others are as model input.","metadata":{}},{"cell_type":"code","source":"import torch\n\nY = torch.tensor(df.Survived)\n\nindep_cols = ['Age', 'SibSp', 'Parch', 'Fare'] + added_cols\nX = torch.tensor(df[indep_cols].values, dtype=torch.float)\n\nprint('Input shape: ', X.shape)\nprint('Target shape', Y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.160156Z","iopub.execute_input":"2023-09-10T16:15:37.160942Z","iopub.status.idle":"2023-09-10T16:15:37.176605Z","shell.execute_reply.started":"2023-09-10T16:15:37.160896Z","shell.execute_reply":"2023-09-10T16:15:37.175282Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Input shape:  torch.Size([891, 12])\nTarget shape torch.Size([891])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Building a linear model","metadata":{}},{"cell_type":"markdown","source":"$$\nY = WX\n$$","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(0)\n\nnum_features = X.shape[1]\nW = torch.rand(num_features)-0.5\n\nprint('W shape: ', W.shape)\nprint(W)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.177736Z","iopub.execute_input":"2023-09-10T16:15:37.178073Z","iopub.status.idle":"2023-09-10T16:15:37.193066Z","shell.execute_reply.started":"2023-09-10T16:15:37.178044Z","shell.execute_reply":"2023-09-10T16:15:37.191851Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"W shape:  torch.Size([12])\ntensor([-0.0037,  0.2682, -0.4115, -0.3680, -0.1926,  0.1341, -0.0099,  0.3964,\n        -0.0444,  0.1323, -0.1511, -0.0983])\n","output_type":"stream"}]},{"cell_type":"code","source":"pred = torch.matmul(W, X.T)\n\nprint('pred shape: ', pred.shape)\nprint(pred[:10])","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.195628Z","iopub.execute_input":"2023-09-10T16:15:37.196036Z","iopub.status.idle":"2023-09-10T16:15:37.203663Z","shell.execute_reply.started":"2023-09-10T16:15:37.195999Z","shell.execute_reply":"2023-09-10T16:15:37.202486Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"pred shape:  torch.Size([891])\ntensor([ -2.8171, -25.8476,  -3.0221, -19.3761,  -3.4284,  -3.5903, -19.5867,\n         -7.7045,  -5.0294, -10.1865])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The model weights are generated randomly. So the current predictions are not going to be any use. To train the linear model, we need to define the loss firstly. Here, we simply use the absolute error as the loss.","metadata":{}},{"cell_type":"code","source":"loss = torch.abs(pred - Y).mean()\n\nprint('loss: ', loss)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.205093Z","iopub.execute_input":"2023-09-10T16:15:37.205817Z","iopub.status.idle":"2023-09-10T16:15:37.214458Z","shell.execute_reply.started":"2023-09-10T16:15:37.205786Z","shell.execute_reply":"2023-09-10T16:15:37.213380Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"loss:  tensor(12.4397)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Leverage PyTorch to calculate the gradients. We need to call the function `requires_grad_` before calculating loss.","metadata":{}},{"cell_type":"code","source":"W.requires_grad_()","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.216129Z","iopub.execute_input":"2023-09-10T16:15:37.216619Z","iopub.status.idle":"2023-09-10T16:15:37.225032Z","shell.execute_reply.started":"2023-09-10T16:15:37.216579Z","shell.execute_reply":"2023-09-10T16:15:37.224277Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"tensor([-0.0037,  0.2682, -0.4115, -0.3680, -0.1926,  0.1341, -0.0099,  0.3964,\n        -0.0444,  0.1323, -0.1511, -0.0983], requires_grad=True)"},"metadata":{}}]},{"cell_type":"code","source":"pred = torch.matmul(W, X.T)\nloss = torch.abs(pred - Y).mean()\n\nloss.backward()\n\nprint(W.grad)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.225903Z","iopub.execute_input":"2023-09-10T16:15:37.226231Z","iopub.status.idle":"2023-09-10T16:15:37.239033Z","shell.execute_reply.started":"2023-09-10T16:15:37.226204Z","shell.execute_reply":"2023-09-10T16:15:37.237836Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"tensor([-28.2437,  -0.5230,  -0.3816, -32.2042,  -0.6341,  -0.3524,  -0.2424,\n         -0.1930,  -0.5511,  -0.1886,  -0.0864,  -0.7116])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Notice that the gradients will be accumulated by default. Therefore, if we don't want the gradients to be accumulated, we should clear the gradients by call the `zero_` function of the gradients object after updating the model parameters.","metadata":{}},{"cell_type":"code","source":"learning_rate = 0.1\nwith torch.no_grad():\n    W.sub_(W.grad * learning_rate)\n    W.grad.zero_()","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.240952Z","iopub.execute_input":"2023-09-10T16:15:37.241350Z","iopub.status.idle":"2023-09-10T16:15:37.247275Z","shell.execute_reply.started":"2023-09-10T16:15:37.241310Z","shell.execute_reply":"2023-09-10T16:15:37.246017Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"markdown","source":"Before model training, we should split the dataset into two parts: one for training (training set) and one for validation (validation set). Training set is used to train the model, and the validation set is used to evaluate the performance of the current model.\n\nIt is not resonable to evaluate the model according to the performance of the model on the training set since the model has seen the training set. It is better to use another dataset that the model has not seen. That's why we split the dataset into training set and validation set.","metadata":{}},{"cell_type":"code","source":"from fastai.data.transforms import RandomSplitter\n\ntrn_split, val_split = RandomSplitter(seed=0, valid_pct=0.2)(df)\ntrn_X,val_X = X[trn_split],X[val_split]\ntrn_Y,val_Y = Y[trn_split],Y[val_split]\n\nvals, indices = trn_X.max(dim=0)\ntrn_X = trn_X / vals\nvals, indices = val_X.max(dim=0)\nval_X = val_X / vals\n\nprint('#Training set: ', len(trn_X))\nprint('#Validation set: ', len(val_X))","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.248548Z","iopub.execute_input":"2023-09-10T16:15:37.248877Z","iopub.status.idle":"2023-09-10T16:15:37.265047Z","shell.execute_reply.started":"2023-09-10T16:15:37.248848Z","shell.execute_reply":"2023-09-10T16:15:37.263819Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"#Training set:  713\n#Validation set:  178\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Start training now! Let's define some functions:","metadata":{}},{"cell_type":"code","source":"def predict(W, x):\n    return torch.matmul(W, x.T)\n\ndef loss_fn(pred, target):\n    return torch.abs(pred - target).mean()\n\ndef optimize(W, learning_rate):\n    W.sub_(W.grad * learning_rate)\n    W.grad.zero_()\n\ndef one_epoch(W, x, y, learning_rate):\n    pred = predict(W, x)\n    loss = loss_fn(pred, y)\n    loss.backward()\n    with torch.no_grad():\n        optimize(W, learning_rate)\n    return loss.item()\n\ndef init_w(num_features):\n    W = torch.rand(num_features)-0.5\n    W.requires_grad_()\n    return W\n\ndef train_model(X, Y, epochs=50, lr=0.0005):\n    torch.manual_seed(0)\n    W = init_w(X.shape[1])\n    for i in range(epochs):\n        loss = one_epoch(W, X, Y, learning_rate=lr)\n    print('Final loss: ', loss)\n    return W","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.266681Z","iopub.execute_input":"2023-09-10T16:15:37.267085Z","iopub.status.idle":"2023-09-10T16:15:37.275994Z","shell.execute_reply.started":"2023-09-10T16:15:37.267052Z","shell.execute_reply":"2023-09-10T16:15:37.274978Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"markdown","source":"Then we can train a model by calling the `train_model` function.","metadata":{}},{"cell_type":"code","source":"W = train_model(trn_X, trn_Y, 1000, 0.005)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:18:26.423203Z","iopub.execute_input":"2023-09-10T16:18:26.423608Z","iopub.status.idle":"2023-09-10T16:18:26.635353Z","shell.execute_reply.started":"2023-09-10T16:18:26.423577Z","shell.execute_reply":"2023-09-10T16:18:26.634158Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"Final loss:  0.2253539115190506\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"markdown","source":"Use the model to predict the results on the validation set.","metadata":{}},{"cell_type":"code","source":"pred = predict(W, val_X)\nloss = loss_fn(pred, val_Y)\n\nresults = val_Y.bool() == (pred > 0.5)\n\nprint('Loss: ', loss)\nprint('Pred: ', pred[:10])\nprint('Target: ', val_Y[:10])\nprint('Accuracy: ', results.float().mean().item())","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:15:37.507636Z","iopub.execute_input":"2023-09-10T16:15:37.508157Z","iopub.status.idle":"2023-09-10T16:15:37.516847Z","shell.execute_reply.started":"2023-09-10T16:15:37.508126Z","shell.execute_reply":"2023-09-10T16:15:37.515706Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"Loss:  tensor(0.2580, grad_fn=<MeanBackward0>)\nPred:  tensor([-0.0070, -0.0012, -0.0353, -0.0821,  0.9842, -0.1535, -0.1110,  1.0112,\n         0.9232,  0.0073], grad_fn=<SliceBackward0>)\nTarget:  tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 1])\nAccuracy:  0.7696629166603088\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Submitting to Kaggle","metadata":{}},{"cell_type":"code","source":"tst_df = pd.read_csv('/kaggle/input/titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:16:24.432291Z","iopub.execute_input":"2023-09-10T16:16:24.432696Z","iopub.status.idle":"2023-09-10T16:16:24.442637Z","shell.execute_reply.started":"2023-09-10T16:16:24.432660Z","shell.execute_reply":"2023-09-10T16:16:24.441468Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"In this case, it turns out that the test set is missing Fare for one passenger. We'll just fill it with 0 to avoid problems:","metadata":{}},{"cell_type":"code","source":"tst_df['Fare'] = tst_df.Fare.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:16:25.962979Z","iopub.execute_input":"2023-09-10T16:16:25.963400Z","iopub.status.idle":"2023-09-10T16:16:25.970379Z","shell.execute_reply.started":"2023-09-10T16:16:25.963368Z","shell.execute_reply":"2023-09-10T16:16:25.968934Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"Now we can just copy the same steps we did to our training set and do the same exact things on our test set to preprocess the data:","metadata":{}},{"cell_type":"code","source":"tst_df.fillna(modes, inplace=True)\ntst_df = pd.get_dummies(tst_df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\ntst_df[added_cols] = tst_df[added_cols].astype(int)\ntst_X = torch.tensor(tst_df[indep_cols].values, dtype=torch.float)\nvals, indices = tst_X.max(dim=0)\ntst_X = tst_X / vals","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:16:28.440758Z","iopub.execute_input":"2023-09-10T16:16:28.441780Z","iopub.status.idle":"2023-09-10T16:16:28.462678Z","shell.execute_reply.started":"2023-09-10T16:16:28.441741Z","shell.execute_reply":"2023-09-10T16:16:28.461698Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"Let's calculate our predictions of which passengers survived in the test set:","metadata":{}},{"cell_type":"code","source":"tst_df['Survived'] = (predict(tst_X, W) > 0.5).int()","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:16:31.321104Z","iopub.execute_input":"2023-09-10T16:16:31.321834Z","iopub.status.idle":"2023-09-10T16:16:31.327593Z","shell.execute_reply.started":"2023-09-10T16:16:31.321798Z","shell.execute_reply":"2023-09-10T16:16:31.326515Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"The sample submission on the Kaggle competition site shows that we're expected to upload a CSV with just `PassengerId` and `Survived`, so let's create that and save it:","metadata":{}},{"cell_type":"code","source":"sub_df = tst_df[['PassengerId','Survived']]\nsub_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:16:34.326985Z","iopub.execute_input":"2023-09-10T16:16:34.327704Z","iopub.status.idle":"2023-09-10T16:16:34.335533Z","shell.execute_reply.started":"2023-09-10T16:16:34.327668Z","shell.execute_reply":"2023-09-10T16:16:34.334209Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":"We can check the first few rows of the file to make sure it looks reasonable:","metadata":{}},{"cell_type":"code","source":"!head submission.csv","metadata":{"execution":{"iopub.status.busy":"2023-09-10T16:16:39.898705Z","iopub.execute_input":"2023-09-10T16:16:39.899094Z","iopub.status.idle":"2023-09-10T16:16:40.919541Z","shell.execute_reply.started":"2023-09-10T16:16:39.899063Z","shell.execute_reply":"2023-09-10T16:16:40.918269Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"PassengerId,Survived\n892,0\n893,1\n894,0\n895,0\n896,1\n897,0\n898,1\n899,0\n900,1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"When you click \"Submit\" in Kaggle, and wait for the notebook to run, you'll see that your results have been submitted to the competition.","metadata":{}}]}